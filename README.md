# AI_test_task_404SSNoF

## **1. Опис проєкту**
Проєкт автоматизує аналіз роботи служби підтримки за допомогою AI-інструментів. Система виконує дві основні задачі: генерує синтетичний датасет діалогів між клієнтом та агентом підтримки, а також глибоко аналізує кожен діалог.

Розподіл моделей:
    - Генерація діалогів: Використовується локальна модель llama3:8b для створення реалістичних сценаріїв з різними темами, ступенем задоволеності клієнта, а також з "прихованою незадоволеністю".
    - Аналіз діалогів: Використовує LLM Gemini через API для семантичного розбору тексту та оцінки якості.

Система здатна виявляти як явну, так і приховану незадоволеність (коли клієнт формально дякує, але проблема фактично не вирішена).

Після запуску, якщо ви це зробите з уже сгенерованими даними, ви побачити не дуже привабливі результати: середня оцінка 2.8, проблемнийх чатів 83 з 100. Але це не помилка. Якщо подивитися у кінець chat_dataset.json там можна буде побачити, що 60% чатів були сгенеровані поганими, а інші 23 додались через строге визначення "прихованої незадоволеності" у analyze.py, яка автоматично, якщо її знаходила, навіть якщо в сгенерованому датасеті була позначка, що все пройшло добре, на аналізі буде стояти "unsatisfied". 

## **2. Що визначає система**
Для кожного чату аналізатор автоматично визначає:
    - Intent (тему) звернення: payment_issue, technical_error, account_access, tariff_question, refund_request, other.
    - Задоволеність клієнта (Satisfaction): satisfied, neutral, unsatisfied. Прихована незадоволеність вираховується за окремими правилами, прописаними в промпті.
    - Quality score: 
        1 - дуже низька якість підтримки
        2 - слабка обробка звернення
        3 - середній рівень
        4 - хороша підтримка
        5 - відмінна підтримка
    - Agent mistakes: ignored_question, incorrect_info, rude_tone, no_resolution, unnecessary_escalation.

## **3. Технічні особливості та архітектура**
    analyze.py:
     - Pydantic validation: використання строгої схеми Pydantic для жорсткої типізації. Вивід строго у JSON-форматі.
     - Smart Batching + XML-розмітка: для оптимізації запитів до API Gemini використовується пакетна обробка із застосуванням XML-розмітки для ізоляції контексту, а також збільшення фактичного ліміту проаналізованих даних без втрати якості аналізу.
     - Rate Limit Control: система проактивної паузи та retry-логіки для безпечного обходу обмежень API.
     - Контроль якості промптів: категорії intent і помилки агента мають фіксований перелік, а промпти містять чіткі правила оцінювання.

    generate.py:
     - Кожен діалог має:
        1. id – унікальний номер
        2. scenario – тема звернення
        3. case_type – тип кейсу (успішний, проблемний, конфлікт)
        4. agent_mistake – список можливих помилок агента
        5. passive_agression – ознака пасивної агресії клієнта
        6. messages – масив повідомлень (role + text)
    - Валідація гарантує, що:
      повідомлення мають правильну структуру
      кількість повідомлень у діапазоні 3–12
      ролі повідомлень тільки client або agent
    - Очищення тексту – видаляє зайві пробіли і символи переносу рядка.
    - Рекурсивна генерація – якщо діалог не пройшов валідацію, він генерується з новим dialog_id, щоб уникнути некоректних даних.

    translator.py
      - Ділить діалоги на батчі.
      - Створює payload для моделі, включаючи тільки id і messages.
      - Замінює у вихідному датасеті тільки messages на перекладені.

## **4. Структура проєкту:**
* `generate.py` - генерація діалогів через локальну LLM;
* `analyze.py` - аналіз діалогів між клієнтом та агентом за допомогою Gemini API та формування JSON-результатів;
* `FrontStart.py` - веб-вітрина на основі Streamlit для візуалізації результатів;
* `requirements.txt` - список залежностей Python;
* `Dockerfile` - конфігурація для контейнеризації та швидкого розгортання вітрини.
* `translator.py` - переклад чатів на українську

## **5. Встановлення та запуск**
    1. Клонувати репозиторій та перейти до папки проєкту.
    2. Створити файл .env у корені проєкту та додати туди ваш ключ API: GEMINI_API_KEY=ваш_ключ, GEMINI_API_KEY_TRS_ANAL=ваш_ключ
    3. Встановити залежності, зазначені у requirements.txt: pip install -r requirements.txt
    4. Згенерувати датасет запустивши скрипт: python generate.py
    5. Перекласти чати на українську: python translator.py
    6. Проаналізувати згенеровані JSON-файл: python analyze.py
    7. Запустити сайт через команду в терміналі: streamlit run FrontStart.py

    Якщо Ви плануєте запустити проєкт через Docker з уже готовими JSON-файлами, виконайте дві команди:
    docker build -t skelar_testtask_app .
    docker run -p 8501:8501 skelar_testtask_app

### **6. Автори**
* **Triadnia**
  * Role: team lead, analyst
  * Gmail: spacea624@gmail.com
* **gokpyt**
  * Role: frontend
  * Gmail: kolakizim@gmail.com 
* **EllionChi**
  * Role: generate dataset
  * Gmail: edik.sidorenko.2016@gmail.com
* **zlatiKf**
  * Role: Prompt Engineering
  * Gmail: flowmorrann@gmail.com
