# AI_test_task_404SSNoF

## **1. Опис проєкту**
Проєкт автоматизує аналіз роботи служби підтримки за допомогою AI-інструментів. Система виконує дві основні задачі: генерує синтетичний датасет діалогів між клієнтом та агентом підтримки, а також глибоко аналізує кожен діалог.

Розподіл моделей:
    - Генерація діалогів: Використовується локальна модель ____ для створення реалістичних сценаріїв з різними темами, ступенем задоволеності клієнта, а також з "прихованою незадоволеністю".
    - Аналіз діалогів: Використовує LLM Gemini через API для семантичного розбору тексту та оцінки якості.

Система здатна виявляти як явну, так і приховану незадоволеність (коли клієнт формально дякує, але проблема фактично не вирішена).

## **2. Що визначає система**
Для кожного чату аналізатор автоматично визначає:
    - Intent (тему) звернення: payment_issue, technical_error, account_access, tariff_question, refund_request, other.
    - Задоволеність клієнта (Satisfaction): satisfied, neutral, unsatisfied. Прихована незадоволеність вираховується за окремими правилами, прописаними в промпті.
    - Quality score: 
        1 - дуже низька якість підтримки
        2 - слабка обробка звернення
        3 - середній рівень
        4 - хороша підтримка
        5 - відмінна підтримка
    - Agent mistakes: ignored_question, incorrect_info, rude_tone, no_resolution, unnecessary_escalation.

## **3. Технічні особливості та архітектура**
    analyze.py:
     - Pydantic validation: використання строгої схеми Pydantic для жорсткої типізації. Вивід строго у JSON-форматі.
     - Smart Batching + XML-розмітка: для оптимізації запитів до API Gemini використовується пакетна обробка із застосуванням XML-розмітки для ізоляції контексту, а також збільшення фактичного ліміту проаналізованих даних без втрати якості аналізу.
     - Rate Limit Control: система проактивної паузи та retry-логіки для безпечного обходу обмежень API.
     - Контроль якості промптів: категорії intent і помилки агента мають фіксований перелік, а промпти містять чіткі правила оцінювання.

    generate.py:
     - [ТУТ ПОКИ ПУСТО]

## **4. Структура проєкту:**
* `generate.py` - генерація діалогів через локальну LLM;
* `analyze.py` - аналіз діалогів між клієнтом та агентом за допомогою Gemini API та формування JSON-результатів;
* `FrontStart.py` - веб-вітрина на основі Streamlit для візуалізації результатів;
* `requirements.txt` - список залежностей Python;
* `Dockerfile` - конфігурація для контейнеризації та швидкого розгортання вітрини.

## **5. Встановлення та запуск**
    1. Клонувати репозиторій та перейти до папки проєкту.
    2. Створити файл .env у корені проєкту та додати туди ваш ключ API: GEMINI_API_KEY=ваш_ключ
    3. Встановити залежності, зазначені у requirements.txt: pip install -r requirements.txt
    4. Згенерувати датасет запустивши скрипт: python generate.py
    5. Проаналізувати згенерований JSON-файл: python analyze.py
    6. Запустити сайт через команду в терміналі: streamlit run FrontStart.py

    Якщо Ви плануєте запустити проєкт через Docker з уже готовими JSON-файлами, виконайте дві команди:
    docker build -t skelar_testtask_app .
    docker run -p 8501:8501 skelar_testtask_app

### **6. Автори**
* **Triadnia**
  * Role: team lead, analyst
  * Gmail: spacea624@gmail.com
* **gokpyt**
  * Role: frontend
  * Gmail: kolakizim@gmail.com 
* **EllionChi**
  * Role: generate dataset
  * Gmail: edik.sidorenko.2016@gmail.com
* **zlatiKf**
  * Role: Prompt Engineering
  * Gmail: flowmorrann@gmail.com